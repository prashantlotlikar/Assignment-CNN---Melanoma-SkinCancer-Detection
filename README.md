# Project Name
- Melanoma Skin Cancer Detection


# Problem Statement
- Problem statement: To build a CNN based model which can accurately detect melanoma.


# Methodology and results 

## 1. Data Reading/Data Understanding → Defining the path for train and test images
- mount google drive
- unzip the dataset from google drive
- Defining the path for train and test images from google drive
- Count the number of image in Train and Test directory Using the glob to retrieve files/pathnames matching a specified pattern.

-- Count : Train 2239 / Test 118
	
## 2. Dataset Creation→ Create train & validation dataset from the train directory with a batch size of 32. Also, make sure you resize your images to 180*180.
- Visualize one instance of all the class present in the dataset.
-- Found 2239 files belonging to 9 classes.


## 3. Dataset visualisation → Create a code to visualize one instance of all the nine classes present in the dataset
- Visualize distribution of classes in the training dataset.

                        Class  Count
0                    melanoma    438
1  pigmented benign keratosis    462
2     squamous cell carcinoma    181
3        basal cell carcinoma    376
4        seborrheic keratosis     77
5              dermatofibroma     95
6                       nevus    357
7             vascular lesion    139
8           actinic keratosis    114

- Image

## 4. Class distribution: → Examine the current class distribution in the training dataset
- Image
-
## 5. Handling class imbalances: → Rectify class imbalances present in the training dataset with Augmentor library.

## 6. Class distribution: → Examine the current class distribution in the training dataset

## 7. Chose an appropriate data augmentation strategy to resolve underfitting/overfitting
- Adding 500 samples per class to make sure that none of the classes are sparse in training dataset
- Count total number of image generated by Augmentor.
-- 4500
-
-
-
## 8. Model Building & training on the augmented data :
--	 Found 6739 files belonging to 9 classes.Using 5392 files for training.
-- Found 6739 files belonging to 9 classes. Using 1347 files for validation.

-  Create a CNN model, which can accurately detect 9 classes present in the dataset. While building the model rescale images to normalize pixel values between (0,1).

Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 rescaling (Rescaling)       (None, 180, 180, 3)       0         
                                                                 
 conv2d (Conv2D)             (None, 178, 178, 32)      896       
                                                                 
 max_pooling2d (MaxPooling2  (None, 89, 89, 32)        0         
 D)                                                              
                                                                 
 conv2d_1 (Conv2D)           (None, 87, 87, 64)        18496     
                                                                 
 max_pooling2d_1 (MaxPoolin  (None, 43, 43, 64)        0         
 g2D)                                                            
                                                                 
 conv2d_2 (Conv2D)           (None, 41, 41, 128)       73856     
                                                                 
 max_pooling2d_2 (MaxPoolin  (None, 20, 20, 128)       0         
 g2D)                                                            
                                                                 
 dropout (Dropout)           (None, 20, 20, 128)       0         
                                                                 
 flatten (Flatten)           (None, 51200)             0         
                                                                 
 dense (Dense)               (None, 128)               6553728   
                                                                 
 dropout_1 (Dropout)         (None, 128)               0         
                                                                 
 dense_1 (Dense)             (None, 9)                 1161      
                                                                 
=================================================================
Total params: 6648137 (25.36 MB)
Trainable params: 6648137 (25.36 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________

- Train the model
Epoch 1/20
169/169 [==============================] - ETA: 0s - loss: 1.8506 - accuracy: 0.2969
Epoch 1: val_accuracy improved from -inf to 0.45212, saving model to model.h5
169/169 [==============================] - 41s 91ms/step - loss: 1.8506 - accuracy: 0.2969 - val_loss: 1.5014 - val_accuracy: 0.4521
Epoch 2/20
/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
169/169 [==============================] - ETA: 0s - loss: 1.5055 - accuracy: 0.4262
Epoch 2: val_accuracy did not improve from 0.45212
169/169 [==============================] - 10s 56ms/step - loss: 1.5055 - accuracy: 0.4262 - val_loss: 1.4282 - val_accuracy: 0.4395
Epoch 3/20
169/169 [==============================] - ETA: 0s - loss: 1.3097 - accuracy: 0.4948
Epoch 3: val_accuracy improved from 0.45212 to 0.55679, saving model to model.h5
169/169 [==============================] - 10s 59ms/step - loss: 1.3097 - accuracy: 0.4948 - val_loss: 1.1947 - val_accuracy: 0.5568
Epoch 4/20
169/169 [==============================] - ETA: 0s - loss: 1.2134 - accuracy: 0.5402
Epoch 4: val_accuracy did not improve from 0.55679
169/169 [==============================] - 9s 52ms/step - loss: 1.2134 - accuracy: 0.5402 - val_loss: 1.2296 - val_accuracy: 0.5427
Epoch 5/20
169/169 [==============================] - ETA: 0s - loss: 1.1390 - accuracy: 0.5734
Epoch 5: val_accuracy improved from 0.55679 to 0.59243, saving model to model.h5
169/169 [==============================] - 9s 54ms/step - loss: 1.1390 - accuracy: 0.5734 - val_loss: 1.0779 - val_accuracy: 0.5924
Epoch 6/20
169/169 [==============================] - ETA: 0s - loss: 1.0618 - accuracy: 0.5992
Epoch 6: val_accuracy improved from 0.59243 to 0.63400, saving model to model.h5
169/169 [==============================] - 9s 55ms/step - loss: 1.0618 - accuracy: 0.5992 - val_loss: 1.0044 - val_accuracy: 0.6340
Epoch 7/20
169/169 [==============================] - ETA: 0s - loss: 0.8892 - accuracy: 0.6608
Epoch 7: val_accuracy improved from 0.63400 to 0.67558, saving model to model.h5
169/169 [==============================] - 9s 52ms/step - loss: 0.8892 - accuracy: 0.6608 - val_loss: 0.8970 - val_accuracy: 0.6756
Epoch 8/20
169/169 [==============================] - ETA: 0s - loss: 0.8548 - accuracy: 0.6756
Epoch 8: val_accuracy improved from 0.67558 to 0.71121, saving model to model.h5
169/169 [==============================] - 9s 54ms/step - loss: 0.8548 - accuracy: 0.6756 - val_loss: 0.8211 - val_accuracy: 0.7112
Epoch 9/20
169/169 [==============================] - ETA: 0s - loss: 0.7727 - accuracy: 0.7068
Epoch 9: val_accuracy did not improve from 0.71121
169/169 [==============================] - 9s 52ms/step - loss: 0.7727 - accuracy: 0.7068 - val_loss: 0.8626 - val_accuracy: 0.7053
Epoch 10/20
169/169 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.7391
Epoch 10: val_accuracy did not improve from 0.71121
169/169 [==============================] - 9s 52ms/step - loss: 0.6857 - accuracy: 0.7391 - val_loss: 0.8380 - val_accuracy: 0.7105
Epoch 11/20
168/169 [============================>.] - ETA: 0s - loss: 0.6317 - accuracy: 0.7580
Epoch 11: val_accuracy improved from 0.71121 to 0.74833, saving model to model.h5
169/169 [==============================] - 9s 54ms/step - loss: 0.6300 - accuracy: 0.7587 - val_loss: 0.8154 - val_accuracy: 0.7483
Epoch 12/20
169/169 [==============================] - ETA: 0s - loss: 0.6025 - accuracy: 0.7711
Epoch 12: val_accuracy did not improve from 0.74833
169/169 [==============================] - 9s 53ms/step - loss: 0.6025 - accuracy: 0.7711 - val_loss: 0.8095 - val_accuracy: 0.7350
Epoch 13/20
168/169 [============================>.] - ETA: 0s - loss: 0.5474 - accuracy: 0.7931
Epoch 13: val_accuracy improved from 0.74833 to 0.76244, saving model to model.h5
169/169 [==============================] - 9s 53ms/step - loss: 0.5470 - accuracy: 0.7932 - val_loss: 0.7276 - val_accuracy: 0.7624
Epoch 14/20
169/169 [==============================] - ETA: 0s - loss: 0.5373 - accuracy: 0.8029
Epoch 14: val_accuracy improved from 0.76244 to 0.78693, saving model to model.h5
169/169 [==============================] - 9s 55ms/step - loss: 0.5373 - accuracy: 0.8029 - val_loss: 0.7103 - val_accuracy: 0.7869
Epoch 15/20
168/169 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8157
Epoch 15: val_accuracy did not improve from 0.78693
169/169 [==============================] - 9s 51ms/step - loss: 0.4831 - accuracy: 0.8158 - val_loss: 0.7472 - val_accuracy: 0.7869
Epoch 16/20
169/169 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.8238
Epoch 16: val_accuracy improved from 0.78693 to 0.78990, saving model to model.h5
169/169 [==============================] - 9s 54ms/step - loss: 0.4722 - accuracy: 0.8238 - val_loss: 0.7538 - val_accuracy: 0.7899
Epoch 17/20
169/169 [==============================] - ETA: 0s - loss: 0.4368 - accuracy: 0.8364
Epoch 17: val_accuracy did not improve from 0.78990
169/169 [==============================] - 9s 53ms/step - loss: 0.4368 - accuracy: 0.8364 - val_loss: 0.7508 - val_accuracy: 0.7840
Epoch 18/20
169/169 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.8216
Epoch 18: val_accuracy improved from 0.78990 to 0.80252, saving model to model.h5
169/169 [==============================] - 9s 52ms/step - loss: 0.4672 - accuracy: 0.8216 - val_loss: 0.6898 - val_accuracy: 0.8025
Epoch 19/20
168/169 [============================>.] - ETA: 0s - loss: 0.4034 - accuracy: 0.8440
Epoch 19: val_accuracy improved from 0.80252 to 0.80772, saving model to model.h5
169/169 [==============================] - 9s 53ms/step - loss: 0.4032 - accuracy: 0.8438 - val_loss: 0.7220 - val_accuracy: 0.8077
Epoch 20/20
169/169 [==============================] - ETA: 0s - loss: 0.3540 - accuracy: 0.8605
Epoch 20: val_accuracy improved from 0.80772 to 0.82702, saving model to model.h5
169/169 [==============================] - 9s 55ms/step - loss: 0.3540 - accuracy: 0.8605 - val_loss: 0.6689 - val_accuracy: 0.8270


- # Plot the training curves
image 

## 9.0Model Building & training on the rectified class imbalance data
- 1/1 [==============================] - 0s 27ms/step
Actual Class basal cell carcinoma
Predictive Class basal cell carcinoma